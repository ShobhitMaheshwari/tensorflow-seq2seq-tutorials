{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import helpers\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "UNK = 2\n",
    "\n",
    "#change this to 10 for the original example to work\n",
    "vocab_size = 10\n",
    "input_embedding_size = 20\n",
    "\n",
    "encoder_hidden_units = 20\n",
    "decoder_hidden_units = encoder_hidden_units * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "encoder_inputs2 = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length2 = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "# decoder_lengths = tf.placeholder(shape=(None,), dtype=tf.int32, name='decoder_lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "encoder_inputs_embedded2 = tf.nn.embedding_lookup(embeddings, encoder_inputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n",
    "encoder_cell = LSTMCell(encoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('first'):\n",
    "    ((encoder_fw_outputs,\n",
    "      encoder_bw_outputs),\n",
    "     (encoder_fw_final_state,\n",
    "      encoder_bw_final_state)) = (\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                        cell_bw=encoder_cell,\n",
    "                                        inputs=encoder_inputs_embedded,\n",
    "                                        sequence_length=encoder_inputs_length,\n",
    "                                        dtype=tf.float32, time_major=True)\n",
    "        )\n",
    "with tf.variable_scope('second'):\n",
    "    ((encoder_fw_outputs2,\n",
    "      encoder_bw_outputs2),\n",
    "     (encoder_fw_final_state2,\n",
    "      encoder_bw_final_state2)) = (\n",
    "        tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                        cell_bw=encoder_cell,\n",
    "                                        inputs=encoder_inputs_embedded2,\n",
    "                                        sequence_length=encoder_inputs_length2,\n",
    "                                        dtype=tf.float32, time_major=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'first/bidirectional_rnn/fw/fw/TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'first/ReverseSequence:0' shape=(?, ?, 20) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'first/bidirectional_rnn/fw/fw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'first/bidirectional_rnn/fw/fw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_fw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=<tf.Tensor 'first/bidirectional_rnn/bw/bw/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'first/bidirectional_rnn/bw/bw/while/Exit_3:0' shape=(?, 20) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_bw_final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs2 = tf.concat((encoder_fw_outputs2, encoder_bw_outputs2), 2)\n",
    "\n",
    "encoder_final_state_c2 = tf.concat(\n",
    "    (encoder_fw_final_state2.c, encoder_bw_final_state2.c), 1)\n",
    "\n",
    "encoder_final_state_h2 = tf.concat(\n",
    "    (encoder_fw_final_state2.h, encoder_bw_final_state2.h), 1)\n",
    "\n",
    "encoder_final_state2 = LSTMStateTuple(\n",
    "    c=encoder_final_state_c2,\n",
    "    h=encoder_final_state_h2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_state = LSTMStateTuple(\n",
    "    c=tf.concat([encoder_final_state.c, encoder_final_state2.c], 1),\n",
    "    h=tf.concat([encoder_final_state.h, encoder_final_state2.h], 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_state.c.get_shape().as_list()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A fully connected layer between encoder_final_state.c (encoder_hidden_units) and decoder_hidden_units\n",
    "def multilayer_perceptron(x, w, b):\n",
    "    layer_1 = tf.add(tf.matmul(x, w), b)\n",
    "    return tf.nn.relu(layer_1)\n",
    "    \n",
    "with tf.variable_scope('c'):\n",
    "    wc = tf.Variable(tf.random_normal([combined_state.c.get_shape().as_list()[1], decoder_hidden_units]))\n",
    "    bc = tf.Variable(tf.random_normal([decoder_hidden_units]))\n",
    "    \n",
    "with tf.variable_scope('h'):\n",
    "    wh = tf.Variable(tf.random_normal([combined_state.h.get_shape().as_list()[1], decoder_hidden_units]))\n",
    "    bh = tf.Variable(tf.random_normal([decoder_hidden_units]))\n",
    "projected_state = tf.contrib.rnn.LSTMStateTuple(\n",
    "    c=multilayer_perceptron(combined_state.c, wc, bc),\n",
    "    h=multilayer_perceptron(combined_state.h, wh, bh),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_cell = LSTMCell(decoder_hidden_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_lengths = tf.maximum(encoder_inputs_length, encoder_inputs_length2) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    initial_input = eos_step_embedded\n",
    "    initial_cell_state = projected_state\n",
    "    initial_cell_output = None\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    def get_next_input():\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'TensorArrayStack/TensorArrayGatherV3:0' shape=(?, ?, 40) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_prediction = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head of the batch:\n",
      "[3, 3, 6, 9, 2]\n",
      "[8, 3, 7, 3]\n",
      "[3, 4, 7, 8, 9]\n",
      "[8, 7, 6, 4, 9, 5]\n",
      "[8, 8, 5, 5]\n",
      "[2, 3, 2, 9]\n",
      "[3, 8, 5, 9, 8]\n",
      "[4, 2, 6, 8]\n",
      "[7, 6, 5]\n",
      "[2, 2, 2, 9, 3]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "batches = helpers.random_sequences(length_from=3, length_to=8,\n",
    "                                   vocab_lower=2, vocab_upper=10,\n",
    "                                   batch_size=batch_size)\n",
    "\n",
    "print('head of the batch:')\n",
    "for seq in next(batches)[:10]:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add(batch1, batch2):\n",
    "    targetSeq = []\n",
    "    for i in range(0, max(len(batch1), len(batch2))):\n",
    "        if i >=len(batch1):\n",
    "            targetSeq.append((int)(batch2[i]/2))\n",
    "        elif i >=len(batch2):\n",
    "            targetSeq.append((int)(batch1[i])/2)\n",
    "        else:\n",
    "            targetSeq.append((int)((batch1[i]+batch2[i])/2))\n",
    "    return targetSeq\n",
    "def next_feed():\n",
    "    batch1 = next(batches)\n",
    "    batch2 = next(batches)\n",
    "    encoder_inputs_1, encoder_input_lengths_1 = helpers.batch(batch1)\n",
    "    encoder_inputs_2, encoder_input_lengths_2 = helpers.batch(batch2)\n",
    "    \n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "    [add(x,y)  + [EOS] + [PAD] * 2 for x,y in zip(batch1, batch2)]\n",
    "    )\n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_1,\n",
    "        encoder_inputs_length: encoder_input_lengths_1,\n",
    "        encoder_inputs2: encoder_inputs_2,\n",
    "        encoder_inputs_length2: encoder_input_lengths_2,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 2.5091679096221924\n",
      "  sample 1:\n",
      "    input     > [5 4 9 3 4 8 8 0]\n",
      "    input     > [4 3 7 9 0 0 0 0]\n",
      "    predicted > [4 4 4 4 2 4 4 2 4 2 0]\n",
      "  sample 2:\n",
      "    input     > [4 8 7 4 0 0 0 0]\n",
      "    input     > [5 9 7 3 6 0 0 0]\n",
      "    predicted > [4 4 4 4 2 4 4 2 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 4 9 9 3 7 4 0]\n",
      "    input     > [9 9 9 5 8 6 7 6]\n",
      "    predicted > [4 4 4 4 4 2 2 4 4 2 4]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.9064642786979675\n",
      "  sample 1:\n",
      "    input     > [5 3 4 3 4 6 0 0]\n",
      "    input     > [3 2 4 4 0 0 0 0]\n",
      "    predicted > [4 3 3 3 3 3 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [8 4 7 7 0 0 0 0]\n",
      "    input     > [5 5 2 0 0 0 0 0]\n",
      "    predicted > [6 5 4 3 1 0 0 0 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [3 3 3 8 2 0 0 0]\n",
      "    input     > [6 7 3 9 0 0 0 0]\n",
      "    predicted > [4 4 5 4 1 1 0 0 0 0 0]\n",
      "\n",
      "batch 2000\n",
      "  minibatch loss: 0.6291081309318542\n",
      "  sample 1:\n",
      "    input     > [2 5 3 0 0 0 0 0]\n",
      "    input     > [9 2 9 9 2 0 0 0]\n",
      "    predicted > [5 4 4 4 1 1 0 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [2 3 7 4 0 0 0 0]\n",
      "    input     > [8 6 2 9 9 6 4 0]\n",
      "    predicted > [5 4 4 5 4 2 2 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [5 7 4 9 5 0 0 0]\n",
      "    input     > [2 3 6 8 0 0 0 0]\n",
      "    predicted > [3 5 6 8 2 1 0 0 0 0 0]\n",
      "\n",
      "batch 3000\n",
      "  minibatch loss: 0.4606470763683319\n",
      "  sample 1:\n",
      "    input     > [3 6 8 0 0 0 0 0]\n",
      "    input     > [9 6 6 2 9 5 0 0]\n",
      "    predicted > [6 6 7 2 2 2 1 0 0 0 0]\n",
      "  sample 2:\n",
      "    input     > [4 6 5 7 9 0 0 0]\n",
      "    input     > [6 3 3 5 4 7 3 0]\n",
      "    predicted > [5 4 4 6 5 3 1 1 0 0 0]\n",
      "  sample 3:\n",
      "    input     > [8 3 3 3 0 0 0 0]\n",
      "    input     > [7 9 6 0 0 0 0 0]\n",
      "    predicted > [7 6 4 1 1 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 1000\n",
    "\n",
    "try:\n",
    "    for batch in range(max_batches):\n",
    "        fd = next_feed()\n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "\n",
    "        if batch == 0 or batch % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp1, inp2, pred) in enumerate(zip(fd[encoder_inputs].T, fd[encoder_inputs2].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp1))\n",
    "                print('    input     > {}'.format(inp2))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.4518 after 300100 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb218b80b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
